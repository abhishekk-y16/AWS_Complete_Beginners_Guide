# What is DynamoDB? âš¡

Fully managed NoSQL database with millisecond latency at any scale.

## Core Concept

**DynamoDB** is AWS's fast, scalable NoSQL database - no servers to manage, automatic scaling.

```
Traditional Database (RDS):
â”œâ”€ Fix server size upfront
â”œâ”€ Traffic surge â†’ Slow queries
â”œâ”€ Need read replicas for scale
â”œâ”€ Maintenance overhead
â””â”€ Cost: Fixed + surge costs

DynamoDB:
â”œâ”€ Automatic scaling
â”œâ”€ Always fast (milliseconds)
â”œâ”€ Built-in replication
â”œâ”€ Serverless (no maintenance)
â””â”€ Cost: Per request
```

## Relational vs NoSQL

### SQL Database (RDS)

```
Users Table:
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ID   â”‚ Name        â”‚ Email    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1    â”‚ John        â”‚ j@ex.com â”‚
â”‚ 2    â”‚ Jane        â”‚ j@ex.com â”‚
â”‚ 3    â”‚ Bob         â”‚ b@ex.com â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Structured, rigid schema
```

### NoSQL (DynamoDB)

```
Users Collection:
{
  "user_1": {
    "name": "John",
    "email": "j@ex.com",
    "age": 30,
    "preferences": { "theme": "dark" },
    "tags": ["admin", "active"]
  },
  "user_2": {
    "name": "Jane",
    "email": "j@ex.com",
    "phone": "+1234567890",
    "notifications": ["email", "sms"]
  }
}

Flexible, schema-less
```

## Data Model: Tables & Items

```
Table: Users
â”œâ”€ Partition Key: user_id
â”œâ”€ Sort Key: timestamp
â”‚
â”œâ”€ Item 1:
â”‚  â”œâ”€ user_id: "user_123" (partition key)
â”‚  â”œâ”€ timestamp: 1234567890 (sort key)
â”‚  â”œâ”€ name: "John"
â”‚  â”œâ”€ email: "john@example.com"
â”‚  â””â”€ preferences: { theme: "dark" }
â”‚
â””â”€ Item 2:
   â”œâ”€ user_id: "user_456"
   â”œâ”€ timestamp: 1234567891
   â””â”€ ...
```

## Two Capacity Modes

### On-Demand

```
Pricing: Per request

Configuration:
â”œâ”€ Requests auto-scale automatically
â”œâ”€ No capacity planning needed
â”œâ”€ Predictable pricing

Cost Calculation:
â”œâ”€ Write: $1.25 per million writes
â”œâ”€ Read: $0.25 per million reads
â”œâ”€ Example: 1M reads + 100K writes = $0.30

Use Case:
â”œâ”€ Variable traffic
â”œâ”€ New applications
â”œâ”€ Testing/development
â””â”€ Unpredictable workloads
```

### Provisioned

```
Pricing: Per capacity unit (hourly)

Configuration:
â”œâ”€ Define: Read capacity units (RCUs)
â”œâ”€ Define: Write capacity units (WCUs)
â”œâ”€ Auto-scaling optional

1 RCU = 4KB read per second
1 WCU = 1KB write per second

Example:
â”œâ”€ 100 RCU + 100 WCU
â”œâ”€ Cost: ~$50/month (US East)
â”œâ”€ Throughput: 400KB/s reads, 100KB/s writes

Use Case:
â”œâ”€ Predictable traffic
â”œâ”€ High traffic applications
â”œâ”€ Cost optimization needed
â””â”€ Consistent performance
```

## Query vs Scan

### Query (Fast)

```
Query: Find items by partition + sort key

Query Example:
â”œâ”€ Find: All messages for user_123
â”œâ”€ Partition key: user_id = "user_123"
â”œâ”€ Sort key: timestamp > 1 hour ago
â”œâ”€ Speed: Milliseconds
â””â”€ Efficient: Only scans needed data

Performance:
â”œâ”€ 100KB data size
â”œâ”€ Returned: 2 items (4KB)
â””â”€ Cost: 1 RCU (read 4KB)
```

### Scan (Slow)

```
Scan: Read every item in table

Scan Example:
â”œâ”€ Find: All users with age > 30
â”œâ”€ Must scan: Entire users table
â”œâ”€ Speed: Seconds/minutes
â””â”€ Inefficient: Reads all data

Performance:
â”œâ”€ 100GB table size
â”œâ”€ Returned: 1000 items (400KB)
â””â”€ Cost: Reads all 100GB (inefficient!)

AVOID SCANS IN PRODUCTION!
```

## Global Secondary Indexes (GSI)

Add alternate query patterns:

```
Table: Users
â”œâ”€ Partition Key: user_id
â”œâ”€ Sort Key: timestamp
â”‚
â”œâ”€ GSI 1: email
â”‚  â””â”€ Query: Find user by email (alternative way)
â”‚
â”œâ”€ GSI 2: country
â”‚  â””â”€ Query: Find all users in country
â”‚
â””â”€ GSI 3: created_date
   â””â”€ Query: Find users created in date range

With GSI:
â”œâ”€ Query email (previously needed scan)
â”œâ”€ Query country (previously needed scan)
â””â”€ Query date (previously needed scan)
```

## Consistency Models

### Strong Consistency (Default)

```
Read after Write:

Write: Update user age to 30
    â†“
Read: Immediately read age
    â†“
Result: 30 (latest value)

Latency: ~10ms
Cost: 1 RCU
```

### Eventually Consistent

```
Read after Write (delayed):

Write: Update user age to 30
    â†“
Read: Immediately read age
    â†“
Result: 29 (old value - not propagated yet)
    â†“
Read again: 10ms later
    â†“
Result: 30 (now updated)

Latency: ~5ms (faster!)
Cost: 0.5 RCU (half cost!)

Use When:
â”œâ”€ Slight staleness acceptable
â”œâ”€ Need maximum performance
â””â”€ Cost optimization critical
```

## Real-World Example: Social Media App

```
Tables:

1. Users:
   â”œâ”€ Partition Key: user_id
   â”œâ”€ Data: name, email, profile pic
   â””â”€ GSI: email (find by email)

2. Posts:
   â”œâ”€ Partition Key: user_id
   â”œâ”€ Sort Key: timestamp
   â”œâ”€ Data: content, likes, comments
   â””â”€ GSI: timestamp (latest posts globally)

3. Followers:
   â”œâ”€ Partition Key: follower_id
   â”œâ”€ Sort Key: following_id
   â””â”€ Data: date followed

Queries:

Get user profile:
â””â”€ Query Users by user_id (10ms, 1 RCU)

Get user's posts:
â””â”€ Query Posts (user_id, last 7 days) (50ms, 2 RCU)

Get global timeline:
â””â”€ Query Posts GSI (all recent posts) (100ms, 5 RCU)

Get followers:
â””â”€ Query Followers (follower_id) (15ms, 1 RCU)

Performance: All sub-100ms! âš¡
```

## Streams & Triggers

React to data changes:

```
DynamoDB Stream:
â”œâ”€ Captures: INSERT, UPDATE, DELETE
â”œâ”€ Sends to: Lambda function automatically
â”œâ”€ Example use cases:
â”‚  â”œâ”€ Update search index
â”‚  â”œâ”€ Send notification
â”‚  â”œâ”€ Trigger workflow
â”‚  â””â”€ Audit logging

Flow:
User posts â†’ DynamoDB INSERT
    â†“
DynamoDB Stream triggers Lambda
    â†“
Lambda sends notification: "New post!"
    â†“
Result: Real-time features!
```

## Cost Example

```
Scenario: Chat application (1M monthly active users)

Assumptions:
â”œâ”€ 1M users
â”œâ”€ 100 messages/user/month
â”œâ”€ Total messages: 100M/month

On-Demand Mode:

Writes (100M messages):
â”œâ”€ 100M Ã— $1.25 / 1M = $125

Reads (5x per message):
â”œâ”€ 500M reads
â”œâ”€ 500M Ã— $0.25 / 1M = $125

Storage:
â”œâ”€ 100M messages Ã— 1KB = 100GB
â”œâ”€ 100GB Ã— $0.25/month = $25

Total: ~$275/month

Provisioned Mode (on-demand equivalent):

Writes:
â”œâ”€ 100M writes / (30 days Ã— 86400 seconds) = 38 WCU
â”œâ”€ With buffer: 50 WCU

Reads:
â”œâ”€ 500M reads / (30 days Ã— 86400 seconds) = 193 RCU
â”œâ”€ With buffer: 250 RCU

Cost:
â”œâ”€ 250 RCU: ~$120/month
â”œâ”€ 50 WCU: ~$25/month
â”œâ”€ Storage: $25/month
â””â”€ Total: ~$170/month (saves $105!)
```

## Common Mistakes

### âœ— Mistake 1: Hot Partitions

```
Wrong:
â”œâ”€ Partition key: country (USA heavily used)
â”œâ”€ USA has 10M users
â”œâ”€ EU has 1M users
â”œâ”€ USA requests hit single partition
â””â”€ Throttled! (exceeds partition limit)

Right:
â”œâ”€ Partition key: user_id (distributed)
â”œâ”€ Every user hash across partitions
â”œâ”€ Load evenly distributed
â””â”€ No throttling!
```

### âœ— Mistake 2: Using Scan Instead of Query

```
Wrong:
â”œâ”€ Find user by email
â”œâ”€ Scan entire table
â”œâ”€ 10M table â†’ 10M RCU read! ðŸ’¸
â””â”€ Slow and expensive

Right:
â”œâ”€ Create GSI on email
â”œâ”€ Query by email
â”œâ”€ 1 RCU read
â””â”€ Fast and cheap
```

### âœ— Mistake 3: Overly Large Items

```
Wrong:
â”œâ”€ Store 5MB JSON per item
â”œâ”€ Query returns 5MB each time
â”œâ”€ RCU limit reached
â””â”€ Throttled!

Right:
â”œâ”€ Store small items (< 100KB)
â”œâ”€ Reference large data in S3
â”œâ”€ Fast queries + cheap
â””â”€ Scale easily
```

### âœ— Mistake 4: Wrong Capacity Mode

```
Wrong:
â”œâ”€ Provisioned for unpredictable traffic
â”œâ”€ Traffic spike â†’ Throttled
â”œâ”€ Overprovision to be safe
â””â”€ Wasting money on unused capacity

Right:
â”œâ”€ Unpredictable: Use On-Demand
â”œâ”€ Predictable: Use Provisioned
â””â”€ Right tool for job
```

## Best Practices

âœ… Design partition key for even distribution
âœ… Use GSI for alternate access patterns
âœ… Query instead of Scan
âœ… Enable DynamoDB Streams for event handling
âœ… Set TTL for automatic cleanup
âœ… Enable point-in-time recovery
âœ… Monitor throttling metrics
âœ… Use batch operations
âœ… Compress large data
âœ… Archive old data to S3

## CLI Examples

```bash
# Create table
aws dynamodb create-table \
  --table-name Users \
  --attribute-definitions \
    AttributeName=user_id,AttributeType=S \
  --key-schema \
    AttributeName=user_id,KeyType=HASH \
  --billing-mode PAY_PER_REQUEST

# Put item
aws dynamodb put-item \
  --table-name Users \
  --item '{
    "user_id": {"S": "user_123"},
    "name": {"S": "John"},
    "email": {"S": "john@example.com"}
  }'

# Query items
aws dynamodb query \
  --table-name Users \
  --key-condition-expression "user_id = :uid" \
  --expression-attribute-values '{
    ":uid": {"S": "user_123"}
  }'
```

## Next Steps

â†’ [DynamoDB Queries & Scans](./queries.md) - Query optimization
â†’ [Indexes](./indexes.md) - GSI and LSI
â†’ [Global Tables](./global.md) - Multi-region replication