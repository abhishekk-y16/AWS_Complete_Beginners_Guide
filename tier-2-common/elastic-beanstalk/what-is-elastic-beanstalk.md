# What is Elastic Beanstalk? ðŸŒ

AWS Platform-as-a-Service for deploying, managing, and auto-scaling web applications.

## Core Concept

**Elastic Beanstalk** abstracts infrastructure complexity. Upload code â†’ Beanstalk handles servers, databases, monitoring.

```
Traditional Deployment:
â”œâ”€ Launch EC2 instances
â”œâ”€ Configure Auto Scaling
â”œâ”€ Setup Load Balancer
â”œâ”€ Install runtime (Python, Node, etc)
â”œâ”€ Deploy code manually
â”œâ”€ Monitor CloudWatch
â””â”€ 1-2 weeks to production

Elastic Beanstalk:
â”œâ”€ Upload code
â”œâ”€ Select environment
â”œâ”€ Click deploy
â””â”€ Live in minutes!
```

## How It Works

```
Beanstalk Architecture:
â”œâ”€ Application: Your code
â”œâ”€ Environment: Deployment instance
â”‚  â”œâ”€ EC2 instances (2-10+)
â”‚  â”œâ”€ Auto Scaling group
â”‚  â”œâ”€ Elastic Load Balancer
â”‚  â”œâ”€ RDS database (optional)
â”‚  â””â”€ CloudWatch monitoring
â”œâ”€ Version: Specific code release
â””â”€ Configuration: Settings (CPU, memory, etc)
```

## Supported Platforms

```
Languages:
â”œâ”€ Node.js (12+, 14+, 16+, 18+)
â”œâ”€ Python (3.7, 3.8, 3.9, 3.10, 3.11)
â”œâ”€ Java (8, 11, 17)
â”œâ”€ Ruby (2.6, 2.7, 3.0, 3.1)
â”œâ”€ Go (1.18+)
â”œâ”€ PHP (7.4, 8.0, 8.1)
â”œâ”€ .NET (3.1, 6.0)
â””â”€ Docker (custom containers)

Auto-selected runtime handles:
â”œâ”€ OS updates
â”œâ”€ Runtime patches
â”œâ”€ Security fixes
â””â”€ Performance optimization
```

## Deployment Strategies

### All-at-Once (0% uptime, fastest)

```
Deploy app v2.0:

Before:
â””â”€ 4 instances running v1.0

Deploy all-at-once:
â”œâ”€ Stop all 4 instances
â”œâ”€ Deploy v2.0 to all
â”œâ”€ Start all instances
â””â”€ DOWNTIME: 2-3 minutes

Use case: Development, low traffic
```

### Rolling (100% uptime, balanced)

```
Deploy app v2.0 to 4 instances:

â”œâ”€ Stop instance #1, deploy v2.0
â”‚  â””â”€ 3 instances serving, 25% capacity
â”œâ”€ Stop instance #2, deploy v2.0
â”‚  â””â”€ 2 instances serving, 50% capacity
â”œâ”€ Stop instance #3, deploy v2.0
â”‚  â””â”€ 1 instance serving, 75% capacity
â””â”€ Stop instance #4, deploy v2.0
   â””â”€ All on v2.0, 100% capacity

Downtime: 0 minutes
Duration: 5-10 minutes
Use case: Production with traffic
```

### Blue-Green (Safe, testable)

```
Setup:
â”œâ”€ Blue environment (v1.0): 4 instances
â””â”€ Green environment (empty)

Deployment:
â”œâ”€ Launch green: Deploy v2.0 to 4 new instances
â”œâ”€ Test green: All traffic still on blue
â”œâ”€ Validate: Green passes smoke tests
â”œâ”€ Switch: Redirect traffic to green
â””â”€ Cleanup: Terminate blue later

Downtime: 0 minutes (traffic switches instantly)
Use case: Critical production (banking, healthcare)
Risk: Lowest (test before going live)
```

## Real-World Example: SaaS App

```
Deployment:

Step 1: Git push
â”œâ”€ git commit -m "Fix homepage"
â””â”€ git push origin main

Step 2: Deploy to Beanstalk
â”œâ”€ AWS console â†’ Upload code
â”œâ”€ Select "Rolling" deployment
â””â”€ Click "Deploy"

Step 3: Beanstalk handles
â”œâ”€ Pull code from S3
â”œâ”€ Update instances (rolling, no downtime)
â”œâ”€ Run health checks
â”œâ”€ Monitor with CloudWatch
â””â”€ Auto-scale if traffic spikes

Result: Live in 3-5 minutes, zero downtime!
```

## Environment Configuration

```
Development Environment:
â”œâ”€ Instance type: t3.micro (free tier eligible)
â”œâ”€ Instances: 1 (cost-optimized)
â”œâ”€ Auto Scaling: Disabled
â”œâ”€ Database: None (use external)
â””â”€ Cost: $0/month (free tier) or ~$5/month

Production Environment:
â”œâ”€ Instance type: t3.small (2 CPU, 2GB RAM)
â”œâ”€ Instances: 2 (high availability)
â”œâ”€ Auto Scaling: 2-10 based on CPU
â”œâ”€ Load Balancer: Application Load Balancer
â”œâ”€ Database: Amazon RDS (Multi-AZ)
â””â”€ Cost: ~$74/month

  Breakdown:
  â”œâ”€ 2Ã— t3.small: $30.88/month
  â”œâ”€ ALB: $16.20/month (+ $0.006/LCU)
  â””â”€ Data transfer: ~$1-3/month
```

## Configuration Management

```
Environment properties:

Application variables:
â”œâ”€ DATABASE_URL=db.example.com
â”œâ”€ API_KEY=secret123
â”œâ”€ ENVIRONMENT=production
â””â”€ DEBUG=false

Platform-specific:
â”œâ”€ Node.js: npm start script
â”œâ”€ Python: WSGI application path
â”œâ”€ Java: JAR file location
â””â”€ Ruby: Gemfile and Procfile

Health checks:
â”œâ”€ Target: /health endpoint
â”œâ”€ Interval: Every 30 seconds
â”œâ”€ Threshold: 3 consecutive failures
â””â”€ Action: Mark unhealthy, replace
```

## Scaling Behavior

```
Auto Scaling policy (production):

Current: 3 instances, 40% average CPU
â”œâ”€ CPUUtilization > 70%: Add 1 instance
â”œâ”€ Wait 5 minutes
â”œâ”€ Check again, add if still high
â””â”€ Max instances: 10

Example spike:
â”œâ”€ T0: 3 instances, 40% CPU
â”œâ”€ T3: Spike! 85% CPU
â”œâ”€ T8: +1 instance (4 total), CPU â†’ 65%
â”œâ”€ T13: Still high, +1 instance (5 total)
â”œâ”€ T18: CPU â†’ 45%, stable
â””â”€ T1800: No change 30 min, -1 instance â†’ 4

No human intervention needed!
```

## Best Practices

âœ… Use rolling deployment for zero downtime
âœ… Test in dev before prod deployment
âœ… Monitor CloudWatch metrics
âœ… Set up database backups (RDS integrated)
âœ… Use SSL/TLS certificates
âœ… Configure auto scaling appropriately
âœ… Version your environments
âœ… Use environment variables for config
âœ… Enable access logs
âœ… Regular environment updates

## Common Mistakes

âœ— Using all-at-once in production (causes downtime)
âœ— Not testing before deployment
âœ— Over-sizing instances (wastes money)
âœ— Not configuring health checks
âœ— Storing secrets in code (use environment variables)
âœ— Not monitoring logs
âœ— Single instance production (no HA)

## Next Steps

â†’ [Deployments](./deployments.md) - Detailed strategies
â†’ [Database Integration](./database.md) - RDS setup
â†’ [Monitoring](./monitoring.md) - CloudWatch integration