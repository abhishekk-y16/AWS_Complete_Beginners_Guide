# S3 Use Cases ğŸ¯

Real-world scenarios where AWS S3 is the perfect storage solution.

## Use Case 1: Static Website Hosting

### Scenario

```
You're building: Portfolio website (HTML, CSS, JavaScript)

Requirements:
â”œâ”€ Serve HTML pages, images, CSS
â”œâ”€ Fast, reliable worldwide access
â”œâ”€ Need HTTPS/SSL
â”œâ”€ Low cost (no server needed)
â””â”€ Auto-scale to traffic spikes

Why S3 is perfect:
â”œâ”€ Static website hosting built-in
â”œâ”€ CloudFront CDN integration (global delivery)
â”œâ”€ HTTPS support with ACM certificates
â”œâ”€ Pay only for what you store + bandwidth
â””â”€ 11 9's durability (99.999999999%)
```

### Architecture

```
Your website files:
â”œâ”€ index.html
â”œâ”€ about.html
â”œâ”€ css/style.css
â”œâ”€ js/app.js
â””â”€ images/logo.png

Upload to S3:
â”œâ”€ Create bucket: my-portfolio-website
â”œâ”€ Upload files
â”œâ”€ Enable static website hosting
â”œâ”€ Set index.html as default

Connect CloudFront CDN:
â”œâ”€ Create distribution
â”œâ”€ Point to S3 bucket
â”œâ”€ Attach SSL certificate
â”œâ”€ Enable caching

Result:
â””â”€ Global access from any region
   â”œâ”€ US: 50ms
   â”œâ”€ Europe: 100ms
   â”œâ”€ Asia: 150ms
   â””â”€ All auto-cached!
```

### Cost Example

```
Small portfolio site:

Data stored:
â”œâ”€ HTML/CSS/JS: 2MB
â”œâ”€ Images: 50MB
â”œâ”€ Total: 52MB
â””â”€ Monthly cost: 52MB Ã— $0.023/GB = $0.001

Bandwidth:
â”œâ”€ Monthly visitors: 10,000
â”œâ”€ Avg page size: 500KB
â”œâ”€ Monthly transfer: 5GB
â”œâ”€ Cost: 5GB Ã— $0.085/GB = $0.43

CDN (CloudFront):
â”œâ”€ Same 5GB served globally
â”œâ”€ Cost: 5GB Ã— $0.085/GB = $0.43

Total monthly: ~$0.87
Annual: ~$10.40

Perfect for: Freelancers, portfolios, blogs
```

## Use Case 2: Mobile App Backend Storage

### Scenario

```
You're building: Photo sharing app (Instagram-like)

Requirements:
â”œâ”€ Store user-uploaded photos
â”œâ”€ Generate thumbnails automatically
â”œâ”€ Serve images fast worldwide
â”œâ”€ Handle millions of photos
â”œâ”€ Create resized versions (mobile, web, high-res)
â”œâ”€ Secure storage (users can't see others' photos)
â””â”€ Archive old photos

Why S3 is perfect:
â”œâ”€ Scales to petabytes automatically
â”œâ”€ Lambda integration: Auto-thumbnail generation
â”œâ”€ Pre-signed URLs: Secure access without secrets
â”œâ”€ Lifecycle rules: Auto-archive old files
â”œâ”€ CloudFront: Fast image delivery
â”œâ”€ Storage classes: Glacier for archives
```

### Architecture

```
User uploads photo
        â”‚
        â–¼
  S3 bucket receives
        â”‚
        â”œâ”€ Triggers Lambda
        â”‚      â”‚
        â”‚      â”œâ”€ Resize to 200Ã—200 (thumbnail)
        â”‚      â”œâ”€ Resize to 800Ã—600 (web)
        â”‚      â””â”€ Keep original (high-res)
        â”‚
        â”œâ”€ Store metadata in DynamoDB
        â”‚   (photo ID, user ID, timestamp)
        â”‚
        â””â”€ CloudFront caches for fast delivery
        
User views photo
        â”‚
        â”œâ”€ App requests from CloudFront
        â”‚  (fast, cached globally)
        â”‚
        â””â”€ If not cached:
           â”œâ”€ Fetch from S3
           â”œâ”€ Cache in CloudFront
           â””â”€ 2nd request instant
```

### Cost Example

```
Growing photo app:

Users: 100,000
Monthly photos: 50,000
Avg photo: 3MB

Storage:
â”œâ”€ Original: 50,000 Ã— 3MB = 150GB
â”œâ”€ Thumbnail: 50,000 Ã— 0.3MB = 15GB
â”œâ”€ Web: 50,000 Ã— 1MB = 50GB
â”œâ”€ Total: 215GB
â”œâ”€ Cost: 215GB Ã— $0.023/GB = $4.95

Requests:
â”œâ”€ Upload requests: 50,000 Ã— $0.0005 = $25
â”œâ”€ Download requests: 500,000 Ã— $0.0004 = $200
â””â”€ Lambda (thumbnail generation): ~$10

CloudFront (image delivery):
â”œâ”€ 500GB served monthly: 500GB Ã— $0.085 = $42.50

Total monthly: ~$282.45
Annual: ~$3,389

Per user (100K users): $0.0282/month
Scales beautifully!
```

## Use Case 3: Data Lake for Analytics

### Scenario

```
You're building: Business data warehouse

Requirements:
â”œâ”€ Store data from multiple sources:
â”‚  â”œâ”€ App databases (via RDS)
â”‚  â”œâ”€ Mobile analytics (logs)
â”‚  â”œâ”€ Web server logs
â”‚  â”œâ”€ CRM data
â”‚  â””â”€ External APIs
â”œâ”€ Query data with SQL (AWS Athena)
â”œâ”€ Create reports and dashboards
â”œâ”€ Archive historical data (years)
â”œâ”€ Keep 5 years of data
â””â”€ Control costs

Why S3 is perfect:
â”œâ”€ Data lake: Central repository
â”œâ”€ Structured (CSV, Parquet) + unstructured (logs)
â”œâ”€ Athena: Query S3 with SQL directly
â”œâ”€ Partitioning: Organize by date, region, etc.
â”œâ”€ Redshift Spectrum: Advanced analytics
â”œâ”€ Lifecycle: Archive to Glacier (90% cheaper)
```

### Architecture

```
Data Sources
â”œâ”€ RDS Database
â”œâ”€ Application Logs
â”œâ”€ Mobile Analytics
â”œâ”€ Web Server Logs
â””â”€ Third-party APIs
        â”‚
        â–¼
    Lambda (ETL)
    â”œâ”€ Transform data
    â”œâ”€ Convert to Parquet (compress)
    â””â”€ Partition by date/region
        â”‚
        â–¼
    S3 Data Lake
    â”œâ”€ Raw data/logs (30 days)
    â”œâ”€ Processed data (Parquet format)
    â””â”€ Historical archive (Glacier)
        â”‚
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚       â”‚           â”‚
    â–¼       â–¼           â–¼
  Athena  Redshift   QuickSight
  (SQL)  (Analytics) (BI Dashboards)
```

### Partitioning Example

```
S3 bucket structure:

s3://my-data-lake/
â”œâ”€ year=2024/
â”‚  â”œâ”€ month=01/
â”‚  â”‚  â”œâ”€ day=01/
â”‚  â”‚  â”‚  â”œâ”€ sales-2024-01-01.parquet
â”‚  â”‚  â”‚  â”œâ”€ users-2024-01-01.parquet
â”‚  â”‚  â”‚  â””â”€ events-2024-01-01.parquet
â”‚  â”‚  â”œâ”€ day=02/
â”‚  â”‚  â”‚  â””â”€ ...
â”‚  â”‚  â””â”€ ...
â”‚  â””â”€ month=02/
â”‚     â””â”€ ...
â””â”€ year=2023/
   â””â”€ ... (archived to Glacier)

Athena query:
SELECT SUM(revenue), region
FROM sales
WHERE year=2024 AND month=01
GROUP BY region;

Bonus: Only scans data in that partition!
Cost: Only charges for data scanned
```

### Cost Example

```
Data lake with 5 years of history:

Data stored:
â”œâ”€ Year 1: 200GB (hot, S3 Standard)
â”œâ”€ Year 2: 200GB (warm, S3-IA)
â”œâ”€ Year 3: 200GB (warm, S3-IA)
â”œâ”€ Year 4: 200GB (cold, Glacier)
â””â”€ Year 5: 200GB (cold, Glacier)

Monthly storage cost:
â”œâ”€ S3 Standard (200GB): 200 Ã— $0.023 = $4.60
â”œâ”€ S3-IA (400GB): 400 Ã— $0.0125 = $5.00
â”œâ”€ Glacier (400GB): 400 Ã— $0.004 = $1.60
â””â”€ Total storage: ~$11.20

Athena queries (assume 50 queries/month):
â”œâ”€ Avg data scanned: 10GB per query
â”œâ”€ Cost: 50 Ã— 10GB Ã— $5/TB = $2.50

Total monthly: ~$13.70
Annual: ~$164.40

Perfect for: Enterprise analytics, regulatory storage
```

## Use Case 4: Backup & Disaster Recovery

### Scenario

```
You're protecting: Database backups, application code

Requirements:
â”œâ”€ Daily backups of production database
â”œâ”€ Version control for code/configs
â”œâ”€ Long-term retention (7 years for compliance)
â”œâ”€ Fast recovery after disaster
â”œâ”€ Encryption for security
â”œâ”€ Geographic redundancy (backup in another region)
â””â”€ Low cost (backups are accessed rarely)

Why S3 is perfect:
â”œâ”€ Durability: 99.999999999% (11 9's)
â”œâ”€ Encryption: Server-side encryption built-in
â”œâ”€ Cross-region replication: Disaster recovery
â”œâ”€ Versioning: Restore any previous version
â”œâ”€ Lifecycle: Auto-archive old backups
â””â”€ Cost: Cheapest long-term storage (Glacier)
```

### Backup Strategy

```
Daily backup process:

1. RDS automated backup
   â””â”€ Snapshots kept for 35 days in AWS

2. Export to S3 (daily)
   â”œâ”€ Database dump: 50GB
   â”œâ”€ Compressed to Parquet: 10GB
   â”œâ”€ Upload to S3 Standard
   â””â”€ Keep for 1 year

3. Weekly full backup
   â””â”€ Keep for 5 years in Glacier

4. Monthly snapshots
   â””â”€ Keep for 7 years in Glacier

Lifecycle rules:
â”œâ”€ 0-30 days: S3 Standard (hot)
â”œâ”€ 30-90 days: S3-IA (warm)
â””â”€ 90+ days: Glacier (cold)

Recovery:
â”œâ”€ Disaster in last 30 days?
â”‚  â””â”€ Restore from S3 Standard (5 min)
â”œâ”€ Disaster in last year?
â”‚  â””â”€ Restore from S3-IA (30 min)
â””â”€ Disaster long ago?
   â””â”€ Restore from Glacier (4 hours)
```

### Cost Example

```
Backup for mid-size company:

Data backed up:
â”œâ”€ RDS database: 500GB
â”œâ”€ Application data: 100GB
â”œâ”€ Code & configs: 10GB
â””â”€ Total: 610GB

Monthly backups stored:

Current month (S3 Standard):
â”œâ”€ 610GB Ã— $0.023 = $14.03

Last 3 months (S3-IA):
â”œâ”€ 3 Ã— 610GB Ã— $0.0125 = $22.88

Last year (Glacier):
â”œâ”€ 9 Ã— 610GB Ã— $0.004 = $21.96

5-year archives (Glacier):
â”œâ”€ 60 Ã— 610GB Ã— $0.004 = $146.40

Total monthly: ~$205.27
Annual: ~$2,463

Value: Can recover from any disaster
ROI: Worth every penny!
```

## Use Case 5: Content Distribution

### Scenario

```
You're running: SaaS application with global users

Requirements:
â”œâ”€ Software downloads (installers, updates)
â”œâ”€ Documentation and help files
â”œâ”€ API assets (icons, logos, images)
â”œâ”€ User-generated content
â”œâ”€ Serve from any location (global)
â”œâ”€ Fast downloads (100+ Mbps)
â”œâ”€ Version control (multiple versions available)
â””â”€ Download analytics

Why S3 is perfect:
â”œâ”€ CloudFront: Distributes globally
â”œâ”€ Pre-signed URLs: Time-limited access
â”œâ”€ Versioning: Multiple versions at once
â”œâ”€ Access logs: Track downloads
â”œâ”€ Bandwidth: Fast worldwide delivery
â”œâ”€ Cost: Pay only for transfer
```

### Distribution Pattern

```
Users worldwide
â”œâ”€ US: Download from edge in Virginia
â”œâ”€ EU: Download from edge in Frankfurt
â”œâ”€ Asia: Download from edge in Singapore
â””â”€ All get: Original from S3 bucket

Speed improvement:
â”œâ”€ Without CloudFront: 500ms (S3 latency)
â”œâ”€ With CloudFront: 50ms (edge server)
â””â”€ Improvement: 10x faster!

Cost:
â”œâ”€ Without CloudFront: $0.09/GB (S3 egress)
â”œâ”€ With CloudFront: $0.085/GB (cheaper!)
â””â”€ Plus: Saves bandwidth costs
```

## Use Case 6: Machine Learning Training Data

### Scenario

```
You're training: ML models on large datasets

Requirements:
â”œâ”€ Store raw data (images, videos, CSV)
â”œâ”€ Organize training/validation/test sets
â”œâ”€ Version datasets (experiment with different versions)
â”œâ”€ Access from SageMaker training jobs
â”œâ”€ Share data across team
â”œâ”€ Keep data organized (1000s of files)
â””â”€ High throughput reading

Why S3 is perfect:
â”œâ”€ SageMaker: Direct integration
â”œâ”€ Multipart upload: Fast uploads
â”œâ”€ Batch operations: Organize 1000s of files
â”œâ”€ Request rate: 3,500 PUTs/1,000 GETs per second
â”œâ”€ Cost: Cheaper than alternatives
â””â”€ Durability: Never lose training data
```

### Organization Example

```
s3://ml-training-data/
â”œâ”€ datasets/
â”‚  â”œâ”€ images-v1/
â”‚  â”‚  â”œâ”€ train/ (80% of data)
â”‚  â”‚  â”œâ”€ validation/ (10%)
â”‚  â”‚  â””â”€ test/ (10%)
â”‚  â”‚
â”‚  â”œâ”€ images-v2/ (improved version)
â”‚  â”‚  â”œâ”€ train/
â”‚  â”‚  â”œâ”€ validation/
â”‚  â”‚  â””â”€ test/
â”‚  â”‚
â”‚  â””â”€ text-corpus/
â”‚     â”œâ”€ raw/
â”‚     â”œâ”€ cleaned/
â”‚     â””â”€ tokenized/
â”‚
â””â”€ models/
   â”œâ”€ model-v1-accuracy-92%.zip
   â”œâ”€ model-v2-accuracy-94%.zip
   â””â”€ model-v3-accuracy-96%.zip

SageMaker can read directly:
â”œâ”€ Training job references S3 path
â”œâ”€ Auto-downloads to training instance
â”œâ”€ Parallel reads across multiple instances
â””â”€ High throughput to GPUs
```

## When NOT to Use S3

```
âŒ Frequently changing data
   â†’ Use: EBS for databases, DynamoDB for NoSQL

âŒ Real-time transactional data
   â†’ Use: RDS, DynamoDB, or Memcached

âŒ High request rate (>1K/sec per object)
   â†’ Use: DynamoDB with caching

âŒ Search within data
   â†’ Use: OpenSearch or Elasticsearch

âŒ Small files with frequent access
   â†’ Use: Database or cache

âŒ Extremely low latency (microseconds)
   â†’ Use: ElastiCache or local storage
```

## Best Practices by Use Case

### Website Hosting
âœ… Enable versioning (rollback capability)
âœ… Use CloudFront CDN (global speed)
âœ… Enable compression (reduce bandwidth)
âœ… Set cache headers (browser caching)
âœ… Use HTTPS with ACM certificate

### Mobile Apps
âœ… Use pre-signed URLs (secure without secrets)
âœ… Generate thumbnails automatically (Lambda)
âœ… Archive old uploads (lifecycle rules)
âœ… Enable transfer acceleration (upload speed)
âœ… Use S3 Intelligent-Tiering

### Data Lakes
âœ… Partition by date/region (query efficiency)
âœ… Use Parquet format (compression + speed)
âœ… Archive old data (cost savings)
âœ… Enable S3 Inventory (track files)
âœ… Use Athena for querying (no servers)

### Backups
âœ… Enable versioning
âœ… Cross-region replication (disaster recovery)
âœ… MFA delete (prevent accidents)
âœ… Lifecycle to Glacier (cost optimization)
âœ… Encryption mandatory

### Content Distribution
âœ… CloudFront mandatory (global speed)
âœ… Enable compression
âœ… Set appropriate cache headers
âœ… Monitor with CloudFront analytics
âœ… Use S3 access logs

## Comparison: S3 vs Alternatives

```
Storage needs       â†’ Best choice
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Static website      â†’ S3 + CloudFront
User files (photos) â†’ S3 + CloudFront
Database backups    â†’ S3 + Glacier
Real-time database  â†’ RDS/DynamoDB
NoSQL JSON data     â†’ DynamoDB
Cache layer         â†’ ElastiCache
Search index        â†’ OpenSearch
Machine learning    â†’ S3 + SageMaker
Logs/time-series    â†’ CloudWatch Logs
Fast disks (DB)     â†’ EBS volumes
```

## Next Steps

â†’ [What is S3](./what-is-s3.md) - Full S3 overview
â†’ [Pricing](./pricing.md) - Cost breakdown
â†’ [Storage Classes](./storage-classes.md) - Choose the right tier
â†’ [Lifecycle Rules](./lifecycle-rules.md) - Automate cost savings